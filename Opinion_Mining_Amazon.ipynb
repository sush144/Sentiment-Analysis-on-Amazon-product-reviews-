{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d44f7c76-db5e-4762-bc2f-384bb5c7c880",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "#import wget\n",
    "from pyspark.ml.feature import Bucketizer,RegexTokenizer,StopWordsRemover,CountVectorizer,IDF\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassificationModel, RandomForestClassifier, GBTClassificationModel, GBTClassifier\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\n",
    "    \"Opinion mining on Amazon Fashion product reviews\"\n",
    ").getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75bba7a8-e560-49e8-937b-4692292c8b27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"/FileStore/tables/All_Beauty_json.gz\"\n",
    "#file_type = \"gz\"\n",
    "\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "Beauty = spark.read.json(file_location)\n",
    "\n",
    "Beauty = Beauty.withColumn(\"text\",concat(col(\"summary\"), lit(\" \"),col(\"reviewText\")))\\\n",
    " .drop(\"helpful\")\\\n",
    " .drop(\"reviewerID\")\\\n",
    " .drop(\"reviewerName\")\\\n",
    " .drop(\"reviewTime\")\\\n",
    " .drop(\"style\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e182c7a8-3e50-4668-9965-5f95a21c4bfd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"/FileStore/tables/AMAZON_FASHION_json.gz\"\n",
    "\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "Fashion = spark.read.json(file_location)\n",
    "\n",
    "Fashion.columns\n",
    "\n",
    "Fashion = Fashion.withColumn(\"text\",concat(col(\"summary\"), lit(\" \"),col(\"reviewText\")))\\\n",
    " .drop(\"helpful\")\\\n",
    " .drop(\"reviewerID\")\\\n",
    " .drop(\"reviewerName\")\\\n",
    " .drop(\"reviewTime\")\\\n",
    " .drop(\"style\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b0ac504-e048-4cad-964a-adbdf5683bae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Out[31]: [('asin', 'string'),\n",
       " ('image', 'array<string>'),\n",
       " ('overall', 'double'),\n",
       " ('reviewText', 'string'),\n",
       " ('summary', 'string'),\n",
       " ('unixReviewTime', 'bigint'),\n",
       " ('verified', 'boolean'),\n",
       " ('vote', 'string'),\n",
       " ('text', 'string')]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Out[31]: [('asin', 'string'),\n ('image', 'array<string>'),\n ('overall', 'double'),\n ('reviewText', 'string'),\n ('summary', 'string'),\n ('unixReviewTime', 'bigint'),\n ('verified', 'boolean'),\n ('vote', 'string'),\n ('text', 'string')]",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Beauty.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e07ecc9-f19f-4f0b-94ab-687c57c07d79",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce  # For Python 3.x\n",
    "from pyspark.sql import DataFrame\n",
    " \n",
    "def unionAll(*dfs):\n",
    "    return reduce(DataFrame.unionAll, dfs)\n",
    " \n",
    "df_union  = unionAll(Beauty,Fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4c6343b-add7-4f16-8a2e-b4f7130bc48f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df.columns)\n",
    "display(df_union.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fe0ba66-2a3b-4e2f-834c-cd96cbf70eac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"/FileStore/tables/reviews_Clothing_Shoes_and_Jewelry_5_json.gz\"\n",
    "file_type = \"gz\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"false\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "clsj = spark.read.json(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1405c4e-2f84-499c-a411-a0c8e68a2598",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"/FileStore/tables/reviews_Beauty_5_json.gz\"\n",
    "file_type = \"gz\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"false\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "bt = spark.read.json(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c4b7422-4129-44cc-a112-5d6c96358adc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_union_2  = unionAll(bt,clsj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a962bb04-af11-498c-977f-81104343a9e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Out[76]: ['asin', 'overall', 'reviewText', 'summary', 'unixReviewTime', 'text']"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Out[76]: ['asin', 'overall', 'reviewText', 'summary', 'unixReviewTime', 'text']",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_union = df_union.drop(\"image\")\\\n",
    "    .drop(\"verified\")\\\n",
    "    .drop(\"vote\")\n",
    "df_union.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "716e40df-8a6a-40ae-b088-95955c4bb4db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "root\n",
       " |-- asin: string (nullable = true)\n",
       " |-- helpful: array (nullable = true)\n",
       " |    |-- element: long (containsNull = true)\n",
       " |-- overall: double (nullable = true)\n",
       " |-- reviewText: string (nullable = true)\n",
       " |-- reviewTime: string (nullable = true)\n",
       " |-- reviewerID: string (nullable = true)\n",
       " |-- reviewerName: string (nullable = true)\n",
       " |-- summary: string (nullable = true)\n",
       " |-- unixReviewTime: long (nullable = true)\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "root\n |-- asin: string (nullable = true)\n |-- helpful: array (nullable = true)\n |    |-- element: long (containsNull = true)\n |-- overall: double (nullable = true)\n |-- reviewText: string (nullable = true)\n |-- reviewTime: string (nullable = true)\n |-- reviewerID: string (nullable = true)\n |-- reviewerName: string (nullable = true)\n |-- summary: string (nullable = true)\n |-- unixReviewTime: long (nullable = true)\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_union_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d7aeac6-3085-4e6e-9c7a-dbc0118d7c42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "root\n",
       " |-- asin: string (nullable = true)\n",
       " |-- overall: double (nullable = true)\n",
       " |-- reviewText: string (nullable = true)\n",
       " |-- summary: string (nullable = true)\n",
       " |-- unixReviewTime: long (nullable = true)\n",
       " |-- text: string (nullable = true)\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "root\n |-- asin: string (nullable = true)\n |-- overall: double (nullable = true)\n |-- reviewText: string (nullable = true)\n |-- summary: string (nullable = true)\n |-- unixReviewTime: long (nullable = true)\n |-- text: string (nullable = true)\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e0bc970-a94f-4df4-893b-f10b6504688c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Out[93]: 477179"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Out[93]: 477179",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_union_2 = df_union_2.withColumn(\"text\",concat(col(\"summary\"), lit(\" \"),col(\"reviewText\")))\\\n",
    " .drop(\"helpful\")\\\n",
    " .drop(\"reviewerID\")\\\n",
    " .drop(\"reviewerName\")\\\n",
    " .drop(\"reviewTime\")\n",
    "df_union_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9bb4753-0c40-4b8a-b389-2851053891b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-------+------------------+\n",
       "|summary|           overall|\n",
       "+-------+------------------+\n",
       "|  count|            477179|\n",
       "|   mean|4.2223610007984425|\n",
       "| stddev|1.1306299814841152|\n",
       "|    min|               1.0|\n",
       "|    max|               5.0|\n",
       "+-------+------------------+\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+-------+------------------+\n|summary|           overall|\n+-------+------------------+\n|  count|            477179|\n|   mean|4.2223610007984425|\n| stddev|1.1306299814841152|\n|    min|               1.0|\n|    max|               5.0|\n+-------+------------------+\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_union_2.describe(\"overall\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfc8fddc-c6c2-4bee-b81f-240b11f9b11d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-------+-----+------+\n",
       "|overall|label| count|\n",
       "+-------+-----+------+\n",
       "|    2.0|  0.0| 26919|\n",
       "|    5.0|  1.0|277771|\n",
       "|    1.0|  0.0| 21718|\n",
       "|    4.0|  1.0| 98098|\n",
       "+-------+-----+------+\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+-------+-----+------+\n|overall|label| count|\n+-------+-----+------+\n|    2.0|  0.0| 26919|\n|    5.0|  1.0|277771|\n|    1.0|  0.0| 21718|\n|    4.0|  1.0| 98098|\n+-------+-----+------+\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Bucketize data and create labels 0 if overall rating is in (1.0,2.0), otherwise 1\n",
    "df1 = df_union_2.filter(\"overall !=3\")\n",
    "\n",
    "splits = [-float(\"inf\"), 4.0, float(\"inf\")]\n",
    "\n",
    "bucketizer = Bucketizer(splits=splits, inputCol=\"overall\", outputCol=\"label\")\n",
    "\n",
    "df2= bucketizer.transform(df1)\n",
    "\n",
    "df2.groupBy(\"overall\",\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6641d954-17d2-4876-82b6-745d17d58259",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-----+-----+\n",
       "|label|count|\n",
       "+-----+-----+\n",
       "|  0.0|48637|\n",
       "|  1.0|37519|\n",
       "+-----+-----+\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+-----+-----+\n|label|count|\n+-----+-----+\n|  0.0|48637|\n|  1.0|37519|\n+-----+-----+\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#take sample to create train and test dataset\n",
    "fractions = {1.0 : .1, 0.0 : 1.0}\n",
    "df3 = df2.stat.sampleBy(\"label\", fractions, 36)\n",
    "df3.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0436a553-1c5e-499b-aca8-562b2de57861",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Split data as 80-20% Train and Test dataset\n",
    "splitSeed = 5043\n",
    "trainingData, testData = df3.randomSplit([0.8, 0.2], splitSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f93600dc-037f-44d2-a863-a1f71e20d759",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Tokenize the sentence based on the regex pattern \n",
    "tokenizer = RegexTokenizer(inputCol=\"text\",outputCol=\"reviewTokensUf\",pattern=\"\\\\s+|[,.()\\\"]\")\n",
    "\n",
    "#Remove Stop Words that do not contribute in any way to our analysis \n",
    "stopwords_remover = StopWordsRemover(stopWords=StopWordsRemover.loadDefaultStopWords(\"english\"),inputCol=\"reviewTokensUf\",outputCol=\"reviewTokens\")\n",
    "\n",
    "#converts word documents to vectors of token counts\n",
    "cv = CountVectorizer(inputCol=\"reviewTokens\",outputCol=\"cv\",vocabSize=296337)\n",
    "\n",
    "#IDF model\n",
    "idf = IDF(inputCol=\"cv\",outputCol=\"features\")\n",
    "\n",
    "#Logistic Boosted Classifier\n",
    "lr = LogisticRegression(maxIter=100,regParam=0.02,elasticNetParam=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0d6ebcb-4f0b-45ba-a3ca-bc84350f1590",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create a pipeline by combining all the functions we defined above - tokenizer , stopwords_remover, cv, idf, gbtc\n",
    "steps =  [tokenizer, stopwords_remover, cv, idf, lr]\n",
    "pipeline = Pipeline(stages=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0397a68a-00b1-49fd-ac17-d778d730be34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#fit the training dataset dataset into the pipeline \n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da607ecf-7c9b-4ba8-b908-b433c370a32c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Obtain the predictions from the model \n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8e67262-69a0-4896-837e-db7fa3807f96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Call the Binary Classification Evaluator function \n",
    "evaluator = BinaryClassificationEvaluator()  \n",
    "areaUnderROC = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6acd100d-72c6-42f3-aa17-21757fb75fa5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#model evaluation\n",
    "lp = predictions.select(\"label\", \"prediction\")\n",
    "counttotal = predictions.count()\n",
    "correct = lp.filter(col(\"label\") == col(\"prediction\")).count()\n",
    "wrong = lp.filter(~(col(\"label\") == col(\"prediction\"))).count()\n",
    "ratioWrong = float(wrong) / float(counttotal)\n",
    "lp = predictions.select(  \"prediction\",\"label\")\n",
    "counttotal = float(predictions.count())\n",
    "correct = lp.filter(col(\"label\") == col(\"prediction\")).count()\n",
    "wrong = lp.filter(\"label != prediction\").count()\n",
    "ratioWrong=wrong/counttotal\n",
    "ratioCorrect=correct/counttotal\n",
    "trueneg =( lp.filter(col(\"label\") == 0.0).filter(col(\"label\") == col(\"prediction\")).count()) /counttotal\n",
    "truepos = (lp.filter(col(\"label\") == 1.0).filter(col(\"label\") == col(\"prediction\")).count())/counttotal\n",
    "falseneg = (lp.filter(col(\"label\") == 0.0).filter(~(col(\"label\") == col(\"prediction\"))).count())/counttotal\n",
    "falsepos = (lp.filter(col(\"label\") == 1.0).filter(~(col(\"label\") == col(\"prediction\"))).count())/counttotal\n",
    "\n",
    "precision= truepos / (truepos + falsepos)\n",
    "recall= truepos / (truepos + falseneg)\n",
    "#fmeasure= 2  precision  recall / (precision + recall)\n",
    "accuracy=(truepos + trueneg) / (truepos + trueneg + falsepos + falseneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5677ba10-f731-465f-a6fd-6e2e427b3771",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "counttotal   : 7598.0\n",
       "correct      : 6597\n",
       "wrong        : 1001\n",
       "ratioWrong   : 0.13174519610423796\n",
       "ratioCorrect : 0.868254803895762\n",
       "truen        : 0.5461963674651223\n",
       "truep        : 0.32205843643063964\n",
       "falsen       : 0.04830218478546986\n",
       "falsep       : 0.08344301131876809\n",
       "precision    : 0.7942226549821487\n",
       "recall       : 0.8695806680881307\n",
       "accuracy     : 0.868254803895762\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "counttotal   : 7598.0\ncorrect      : 6597\nwrong        : 1001\nratioWrong   : 0.13174519610423796\nratioCorrect : 0.868254803895762\ntruen        : 0.5461963674651223\ntruep        : 0.32205843643063964\nfalsen       : 0.04830218478546986\nfalsep       : 0.08344301131876809\nprecision    : 0.7942226549821487\nrecall       : 0.8695806680881307\naccuracy     : 0.868254803895762\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('counttotal   :', counttotal     )\n",
    "print('correct      :', correct        )\n",
    "print('wrong        :', wrong          )\n",
    "print('ratioWrong   :', ratioWrong     )\n",
    "print('ratioCorrect :', ratioCorrect   )\n",
    "print('truen        :', trueneg          )\n",
    "print('truep        :', truepos          )\n",
    "print('falsen       :', falseneg         )\n",
    "print('falsep       :', falsepos         )\n",
    "print('precision    :', precision      )\n",
    "print('recall       :', recall         )\n",
    "#print('fmeasure     :', fmeasure       )\n",
    "print('accuracy     :', accuracy       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9682f326-ee59-4805-9bcc-48aefe0b48b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create a pipeline by combining all the functions we defined above - tokenizer , stopwords_remover, cv, idf, gbtc\n",
    "gbtc = GBTClassifier(maxIter=20)\n",
    "steps =  [tokenizer, stopwords_remover, cv, idf, gbtc]\n",
    "pipeline = Pipeline(stages=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52f80cc9-af68-49e1-b3d3-d0331dc2b23f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "019d3c50-e6ce-4510-a002-495b00e7bcd3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0eb718e2-eab5-42fe-8dd1-596ed8291ffb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator()  \n",
    "areaUnderROC = evaluator.evaluate(predictions)\n",
    "print('Test Area Under ROC', areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffcc2402-0c2b-467c-b768-3f979a2f76c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#model evaluation\n",
    "lp = predictions.select(\"label\", \"prediction\")\n",
    "counttotal = predictions.count()\n",
    "correct = lp.filter(col(\"label\") == col(\"prediction\")).count()\n",
    "wrong = lp.filter(~(col(\"label\") == col(\"prediction\"))).count()\n",
    "ratioWrong = float(wrong) / float(counttotal)\n",
    "lp = predictions.select(  \"prediction\",\"label\")\n",
    "counttotal = float(predictions.count())\n",
    "correct = lp.filter(col(\"label\") == col(\"prediction\")).count()\n",
    "wrong = lp.filter(\"label != prediction\").count()\n",
    "ratioWrong=wrong/counttotal\n",
    "ratioCorrect=correct/counttotal\n",
    "trueneg =( lp.filter(col(\"label\") == 0.0).filter(col(\"label\") == col(\"prediction\")).count()) /counttotal\n",
    "truepos = (lp.filter(col(\"label\") == 1.0).filter(col(\"label\") == col(\"prediction\")).count())/counttotal\n",
    "falseneg = (lp.filter(col(\"label\") == 0.0).filter(~(col(\"label\") == col(\"prediction\"))).count())/counttotal\n",
    "falsepos = (lp.filter(col(\"label\") == 1.0).filter(~(col(\"label\") == col(\"prediction\"))).count())/counttotal\n",
    "\n",
    "precision= truepos / (truepos + falsepos)\n",
    "recall= truepos / (truepos + falseneg)\n",
    "#fmeasure= 2  precision  recall / (precision + recall)\n",
    "accuracy=(truepos + trueneg) / (truepos + trueneg + falsepos + falseneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdfdf8ee-b33a-4e61-99c6-7a96bf3f818c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print('counttotal   :', counttotal     )\n",
    "print('correct      :', correct        )\n",
    "print('wrong        :', wrong          )\n",
    "print('ratioWrong   :', ratioWrong     )\n",
    "print('ratioCorrect :', ratioCorrect   )\n",
    "print('truen        :', trueneg          )\n",
    "print('truep        :', truepos          )\n",
    "print('falsen       :', falseneg         )\n",
    "print('falsep       :', falsepos         )\n",
    "print('precision    :', precision      )\n",
    "print('recall       :', recall         )\n",
    "#print('fmeasure     :', fmeasure       )\n",
    "print('accuracy     :', accuracy       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97ef2348-2955-45d0-9eca-5012a76b51ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create a pipeline by combining all the functions we defined above - tokenizer , stopwords_remover, cv, idf, gbtc\n",
    "bigram = NGram(inputCol = \"tokens\", OutpuCol = \"bigrams\", n = 2)\n",
    "tf5  = HashingTF(inputCol=\"bigrams\", outputCol=\"features\")\n",
    "\n",
    "steps =  [tokenizer, stopwords_remover, bigram, tfs, cv, idf, lr]\n",
    "pipeline = Pipeline(stages=steps)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Opinion_Mining_Amazon",
   "notebookOrigID": 3684231494161189,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
